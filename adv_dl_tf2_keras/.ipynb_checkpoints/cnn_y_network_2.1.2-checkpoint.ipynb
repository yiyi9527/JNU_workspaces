{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03535a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "186a977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f90042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sparse label to categorical\n",
    "num_labels = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91cddf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape and normalize input images\n",
    "image_size = x_train.shape[1]\n",
    "x_train = np.reshape(x_train,[-1, image_size, image_size, 1])\n",
    "x_test = np.reshape(x_test,[-1, image_size, image_size, 1])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff3308d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "input_shape = (image_size, image_size, 1)\n",
    "batch_size = 32\n",
    "kernel_size = 3\n",
    "dropout = 0.4\n",
    "n_filters = 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b523113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# left branch of Y network\n",
    "left_inputs = Input(shape=input_shape)\n",
    "x = left_inputs\n",
    "filters = n_filters\n",
    "# 3 layers of Conv2D-Dropout-MaxPooling2D\n",
    "# number of filters doubles after each layer (32-64-128)\n",
    "for i in range(3):\n",
    "    x = Conv2D(filters=filters,kernel_size=kernel_size,padding='same',activation='relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    filters *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da14b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# right branch of Y network\n",
    "right_inputs = Input(shape=input_shape)\n",
    "y = right_inputs\n",
    "filters = n_filters\n",
    "# 3 layers of Conv2D-Dropout-MaxPooling2Do\n",
    "# number of filters doubles after each layer (32-64-128)\n",
    "for i in range(3):\n",
    "    y = Conv2D(filters=filters,kernel_size=kernel_size,padding='same',activation='relu',dilation_rate=2)(y)\n",
    "    y = Dropout(dropout)(y)\n",
    "    y = MaxPooling2D()(y)\n",
    "    filters *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01870e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge left and right branches outputs\n",
    "y = concatenate([x,y])\n",
    "# feature maps to vector before connecting to Dense\n",
    "y = Flatten()(y)\n",
    "y = Dropout(dropout)(y)\n",
    "outputs = Dense(num_labels,activation='softmax')(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "680e6902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 28, 28, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 28, 28, 32)   320         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 28, 28, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 28, 28, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 14, 14, 32)   0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 32)   0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 64)   18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 14, 14, 64)   18496       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 14, 14, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 14, 14, 64)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 64)     0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 7, 7, 64)     0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 128)    73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 7, 7, 128)    73856       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 128)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 128)    0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 3, 3, 128)    0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3, 3, 256)    0           max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2304)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 2304)         0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           23050       dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 208,394\n",
      "Trainable params: 208,394\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model in functional API\n",
    "model = Model([left_inputs,right_inputs],outputs)\n",
    "# verify the model using graph\n",
    "plot_model(model,to_file='cnn-y-network.png',show_shapes=True)\n",
    "# verify the model using layer text description\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4ff542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier loss, Adam optimizer, classifier accuracy\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "433cb2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 99s 2ms/sample - loss: 0.1106 - acc: 0.9653 - val_loss: 0.1298 - val_acc: 0.9884\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 99s 2ms/sample - loss: 0.0626 - acc: 0.9801 - val_loss: 0.0985 - val_acc: 0.9903\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 101s 2ms/sample - loss: 0.0506 - acc: 0.9839 - val_loss: 0.0725 - val_acc: 0.9909\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 99s 2ms/sample - loss: 0.0461 - acc: 0.9852 - val_loss: 0.0540 - val_acc: 0.9930\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 99s 2ms/sample - loss: 0.0395 - acc: 0.9874 - val_loss: 0.0762 - val_acc: 0.9928\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 100s 2ms/sample - loss: 0.0381 - acc: 0.9883 - val_loss: 0.0398 - val_acc: 0.9940\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 100s 2ms/sample - loss: 0.0360 - acc: 0.9885 - val_loss: 0.0461 - val_acc: 0.9933\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 99s 2ms/sample - loss: 0.0348 - acc: 0.9894 - val_loss: 0.0434 - val_acc: 0.9931\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 99s 2ms/sample - loss: 0.0339 - acc: 0.9897 - val_loss: 0.0572 - val_acc: 0.9930\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 100s 2ms/sample - loss: 0.0307 - acc: 0.9903 - val_loss: 0.0548 - val_acc: 0.9911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d0ae5eaf48>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model with input images and labels\n",
    "model.fit([x_train,x_train],y_train,validation_data=([x_test,x_test],y_test),epochs=10,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e64962f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 99.1%\n"
     ]
    }
   ],
   "source": [
    "# model accuracy on test dataset\n",
    "score = model.evaluate([x_test,x_test],y_test,batch_size=batch_size,verbose=0)\n",
    "print('\\nTest accuracy: %.1f%%' % (100.0 * score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c481d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
